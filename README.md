# Pet_Project

### Briefly about each project:
1. [This assembly code](https://github.com/Sviatoslav1886/Pet_Project/blob/main/Arithmetic_expression_to_file.asm) calculates the expression F=(g+h)âˆ’(i+j) and performs file I/O operations using Linux system calls. The code first computes the sum of g and h, and the sum of i and j, then subtracts the latter from the former to obtain the result stored in F. It then opens a file specified by file_name, writes the value of F to this file, closes the file, and finally displays the value of F on the console followed by a newline character.
2. [This assembly code snippet](https://github.com/Sviatoslav1886/Pet_Project/blob/main/Arithmetic_%D0%BEperations.asm) demonstrates basic arithmetic operations (addition and subtraction) using x86 instructions. Specifically, it performs two operations: adding the values stored in memory locations B and C and then subtracting the value in memory location E from the result. The results are stored in variables A and D, respectively. The code uses Linux system calls (int 0x80) to output the results to the console. This example is useful for understanding low-level operations and system calls in assembly language, illustrating how to manipulate memory and perform arithmetic operations.
3. [This jupyter notebook](https://github.com/Sviatoslav1886/Pet_Project/blob/main/CNN.ipynb) contains a convolutional neural network (CNN) implemented in PyTorch for handwritten digit classification using the MNIST dataset. The code includes data loading, model definition, training, and testing procedures. The CNN architecture consists of two convolutional layers followed by max-pooling, batch normalization, and fully connected layers. The training loop computes loss, performs backpropagation, and updates the model's weights using stochastic gradient descent (SGD). The jupyter notebook also includes a function to predict handwritten digits using the trained model. Additionally, there's an example of predicting a custom image of a digit using OpenCV for preprocessing. The code demonstrates how to handle data loading, preprocessing, model training, evaluation, and inference for image classification tasks using PyTorch and popular computer vision libraries.
4. [This jupyter notebook](https://github.com/Sviatoslav1886/Pet_Project/blob/main/FFNN_diabetes.ipynb) contains a Python script demonstrating the implementation of a neural network for binary classification using PyTorch. The dataset used is the Pima Indians Diabetes Database, preprocessed using standard scaling and converted into PyTorch tensors. The script defines a custom Dataset class for data loading, a neural network model with fully connected layers and activation functions, and trains the model using stochastic gradient descent (SGD) with binary cross-entropy loss. The code showcases batch training with DataLoader, model definition, loss computation, and training loop over specified epochs, printing loss and accuracy metrics per epoch. This example serves as a practical illustration of building and training a neural network for binary classification tasks.
5. [This jupyter notebook](https://github.com/Sviatoslav1886/Pet_Project/blob/main/K_Means_Clustering.ipynb) analyzes a dataset of college information using pandas, seaborn, and scikit-learn. After loading and exploring the data, it visualizes relationships between variables through scatterplots, histograms, and cluster analysis using KMeans. The goal is to understand patterns and potentially classify colleges into private or non-private categories based on their characteristics. The script demonstrates data preprocessing, visualization, and basic machine learning clustering techniques, providing insights into college data and classification performance metrics like confusion matrix and classification report.






