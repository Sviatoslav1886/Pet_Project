{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><span style='color:#F1C40F'>|</span> Preprocess</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sviat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.28M/1.28M [00:00<00:00, 1.35MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading test.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494k/494k [00:00<00:00, 786kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for file in ['train.tsv', 'test.tsv']:\n",
    "    api.competition_download_file('sentiment-analysis-on-movie-reviews', f'{file}.zip', path='./')\n",
    "\n",
    "    with zipfile.ZipFile(f'{file}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./data')\n",
    "\n",
    "    os.remove(f'{file}.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train.tsv', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155984</th>\n",
       "      <td>155985</td>\n",
       "      <td>8540</td>\n",
       "      <td>... either you 're willing to go with this cla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155997</th>\n",
       "      <td>155998</td>\n",
       "      <td>8541</td>\n",
       "      <td>Despite these annoyances , the capable Claybur...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156021</th>\n",
       "      <td>156022</td>\n",
       "      <td>8542</td>\n",
       "      <td>-LRB- Tries -RRB- to parody a genre that 's al...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156031</th>\n",
       "      <td>156032</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156039</th>\n",
       "      <td>156040</td>\n",
       "      <td>8544</td>\n",
       "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8529 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "63            64           2   \n",
       "81            82           3   \n",
       "116          117           4   \n",
       "156          157           5   \n",
       "...          ...         ...   \n",
       "155984    155985        8540   \n",
       "155997    155998        8541   \n",
       "156021    156022        8542   \n",
       "156031    156032        8543   \n",
       "156039    156040        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "63      This quiet , introspective and entertaining in...          4  \n",
       "81      Even fans of Ismail Merchant 's work , I suspe...          1  \n",
       "116     A positively thrilling combination of ethnogra...          3  \n",
       "156     Aggressive self-glorification and a manipulati...          1  \n",
       "...                                                   ...        ...  \n",
       "155984  ... either you 're willing to go with this cla...          2  \n",
       "155997  Despite these annoyances , the capable Claybur...          2  \n",
       "156021  -LRB- Tries -RRB- to parody a genre that 's al...          1  \n",
       "156031  The movie 's downfall is to substitute plot fo...          1  \n",
       "156039  The film is darkly atmospheric , with Herrmann...          2  \n",
       "\n",
       "[8529 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['SentenceId'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "    0 - negative\n",
    "    1 - somewhat negative\n",
    "    2 - neutral\n",
    "    3 - somewhat positive\n",
    "    4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Sentiment'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGrCAYAAAAirYa4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3DElEQVR4nO3de3QV5b3/8U8SyIXL3pFbQhaB0KqEHBEkwbCp2qIpWxt7RKMFSyVCBMHAAaJcohgoxxaLtVzKJbWcGk4rh0tX5WACwZwgYCVyCSIXDVKLBos7CcVkS4QEkvn94S9TdgmWDYSQh/drrVnLzPOdZ76zR1Y+azIzO8CyLEsAAACGCWzuBgAAAJoCIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEitmruB5lRfX69jx46pffv2CggIaO52AADARbAsS19++aWioqIUGHjh6zXXdcg5duyYoqOjm7sNAABwCY4ePapu3bpdcPy6Djnt27eX9PWH5HA4mrkbAABwMbxer6Kjo+3f4xdyXYechj9RORwOQg4AAC3Mv7rVhBuPAQCAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR/Ao5dXV1ev7559WzZ0+FhYXp29/+tv7zP/9TlmXZNZZlKSsrS127dlVYWJiSkpJ0+PBhn3lOnDihESNGyOFwKDw8XGlpaTp58qRPzb59+3TnnXcqNDRU0dHRmjdv3nn9rF27VrGxsQoNDVWfPn20YcMGfw4HAAAYzK+Q84tf/ELLli3T4sWL9eGHH+oXv/iF5s2bp1//+td2zbx587Ro0SJlZ2drx44datu2rdxut06fPm3XjBgxQgcPHlRBQYFyc3O1bds2jR071h73er0aMmSIevTooeLiYr300kuaPXu2XnnlFbtm+/btevTRR5WWlqb33ntPQ4cO1dChQ3XgwIHL+TwAAIApLD8kJydbo0eP9ln30EMPWSNGjLAsy7Lq6+utyMhI66WXXrLHKysrrZCQEOt//ud/LMuyrA8++MCSZO3atcuu2bhxoxUQEGD97W9/syzLspYuXWrdcMMNVk1NjV0zffp0q1evXvbPP/rRj6zk5GSfXhITE60nn3zyoo+nqqrKkmRVVVVd9DYAAKB5Xezvb7+u5AwaNEiFhYX66KOPJEnvv/++/vznP+u+++6TJB05ckQej0dJSUn2Nk6nU4mJiSoqKpIkFRUVKTw8XAkJCXZNUlKSAgMDtWPHDrvmrrvuUnBwsF3jdrt16NAhffHFF3bNuftpqGnYT2Nqamrk9Xp9FgAAYCa/voV8xowZ8nq9io2NVVBQkOrq6vSzn/1MI0aMkCR5PB5JUkREhM92ERER9pjH41GXLl18m2jVSh06dPCp6dmz53lzNIzdcMMN8ng837ifxsydO1c//elP/TlkAADQQvl1JWfNmjV67bXXtHLlSu3Zs0crVqzQL3/5S61YsaKp+ruiMjMzVVVVZS9Hjx5t7pYAAEAT8etKztSpUzVjxgwNHz5cktSnTx99+umnmjt3rlJTUxUZGSlJKisrU9euXe3tysrK1K9fP0lSZGSkysvLfeY9e/asTpw4YW8fGRmpsrIyn5qGn/9VTcN4Y0JCQhQSEuLPIV+2mBl5V3V/TeWTF5ObuwUAAPzi15Wcr776SoGBvpsEBQWpvr5ektSzZ09FRkaqsLDQHvd6vdqxY4dcLpckyeVyqbKyUsXFxXbN5s2bVV9fr8TERLtm27ZtOnPmjF1TUFCgXr166YYbbrBrzt1PQ03DfgAAwPXNr5Dzwx/+UD/72c+Ul5enTz75RK+//rp+9atf6cEHH5QkBQQEaPLkyXrhhRe0fv167d+/XyNHjlRUVJSGDh0qSerdu7fuvfdejRkzRjt37tQ777yjCRMmaPjw4YqKipIk/fjHP1ZwcLDS0tJ08OBBrV69WgsXLlRGRobdy6RJk5Sfn6+XX35ZJSUlmj17tnbv3q0JEyZcoY8GAAC0ZH79uerXv/61nn/+eT311FMqLy9XVFSUnnzySWVlZdk106ZNU3V1tcaOHavKykrdcccdys/PV2hoqF3z2muvacKECbrnnnsUGBiolJQULVq0yB53Op168803lZ6ervj4eHXq1ElZWVk+79IZNGiQVq5cqZkzZ+rZZ5/VTTfdpHXr1umWW265nM8DAAAYIsCyznld8XXG6/XK6XSqqqpKDoejSfbBPTkAAFxZF/v7m++uAgAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABG8ivkxMTEKCAg4LwlPT1dknT69Gmlp6erY8eOateunVJSUlRWVuYzR2lpqZKTk9WmTRt16dJFU6dO1dmzZ31qtmzZov79+yskJEQ33nijcnJyzutlyZIliomJUWhoqBITE7Vz504/Dx0AAJjMr5Cza9cuff755/ZSUFAgSXrkkUckSVOmTNEbb7yhtWvXauvWrTp27Jgeeughe/u6ujolJyertrZW27dv14oVK5STk6OsrCy75siRI0pOTtbgwYO1d+9eTZ48WU888YQ2bdpk16xevVoZGRmaNWuW9uzZo759+8rtdqu8vPyyPgwAAGCOAMuyrEvdePLkycrNzdXhw4fl9XrVuXNnrVy5Ug8//LAkqaSkRL1791ZRUZEGDhyojRs36v7779exY8cUEREhScrOztb06dNVUVGh4OBgTZ8+XXl5eTpw4IC9n+HDh6uyslL5+fmSpMTERA0YMECLFy+WJNXX1ys6OloTJ07UjBkzLrp/r9crp9OpqqoqORyOS/0YvlHMjLwmmfdq++TF5OZuAQAASRf/+/uS78mpra3VH/7wB40ePVoBAQEqLi7WmTNnlJSUZNfExsaqe/fuKioqkiQVFRWpT58+dsCRJLfbLa/Xq4MHD9o1587RUNMwR21trYqLi31qAgMDlZSUZNdcSE1Njbxer88CAADMdMkhZ926daqsrNTjjz8uSfJ4PAoODlZ4eLhPXUREhDwej11zbsBpGG8Y+6Yar9erU6dO6fjx46qrq2u0pmGOC5k7d66cTqe9REdH+3XMAACg5bjkkPNf//Vfuu+++xQVFXUl+2lSmZmZqqqqspejR482d0sAAKCJtLqUjT799FP93//9n/70pz/Z6yIjI1VbW6vKykqfqzllZWWKjIy0a/75KaiGp6/OrfnnJ7LKysrkcDgUFhamoKAgBQUFNVrTMMeFhISEKCQkxL+DBQAALdIlXcl59dVX1aVLFyUn/+Nm1Pj4eLVu3VqFhYX2ukOHDqm0tFQul0uS5HK5tH//fp+noAoKCuRwOBQXF2fXnDtHQ03DHMHBwYqPj/epqa+vV2FhoV0DAADg95Wc+vp6vfrqq0pNTVWrVv/Y3Ol0Ki0tTRkZGerQoYMcDocmTpwol8ulgQMHSpKGDBmiuLg4PfbYY5o3b548Ho9mzpyp9PR0+wrLuHHjtHjxYk2bNk2jR4/W5s2btWbNGuXl/eMppYyMDKWmpiohIUG33367FixYoOrqao0aNepyPw8AAGAIv0PO//3f/6m0tFSjR48+b2z+/PkKDAxUSkqKampq5Ha7tXTpUns8KChIubm5Gj9+vFwul9q2bavU1FTNmTPHrunZs6fy8vI0ZcoULVy4UN26ddPy5cvldrvtmmHDhqmiokJZWVnyeDzq16+f8vPzz7sZGQAAXL8u6z05LR3vybl4vCcHAHCtaPL35AAAAFzLCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEh+h5y//e1v+slPfqKOHTsqLCxMffr00e7du+1xy7KUlZWlrl27KiwsTElJSTp8+LDPHCdOnNCIESPkcDgUHh6utLQ0nTx50qdm3759uvPOOxUaGqro6GjNmzfvvF7Wrl2r2NhYhYaGqk+fPtqwYYO/hwMAAAzlV8j54osv9J3vfEetW7fWxo0b9cEHH+jll1/WDTfcYNfMmzdPixYtUnZ2tnbs2KG2bdvK7Xbr9OnTds2IESN08OBBFRQUKDc3V9u2bdPYsWPtca/XqyFDhqhHjx4qLi7WSy+9pNmzZ+uVV16xa7Zv365HH31UaWlpeu+99zR06FANHTpUBw4cuJzPAwAAGCLAsizrYotnzJihd955R2+//Xaj45ZlKSoqSk8//bSeeeYZSVJVVZUiIiKUk5Oj4cOH68MPP1RcXJx27dqlhIQESVJ+fr5+8IMf6LPPPlNUVJSWLVum5557Th6PR8HBwfa+161bp5KSEknSsGHDVF1drdzcXHv/AwcOVL9+/ZSdnd1ofzU1NaqpqbF/9nq9io6OVlVVlRwOx8V+DH6JmZHXJPNebZ+8mNzcLQAAIOnr399Op/Nf/v7260rO+vXrlZCQoEceeURdunTRbbfdpt/+9rf2+JEjR+TxeJSUlGSvczqdSkxMVFFRkSSpqKhI4eHhdsCRpKSkJAUGBmrHjh12zV133WUHHElyu906dOiQvvjiC7vm3P001DTspzFz586V0+m0l+joaH8OHwAAtCB+hZy//vWvWrZsmW666SZt2rRJ48eP13/8x39oxYoVkiSPxyNJioiI8NkuIiLCHvN4POrSpYvPeKtWrdShQwefmsbmOHcfF6ppGG9MZmamqqqq7OXo0aP+HD4AAGhBWvlTXF9fr4SEBP385z+XJN122206cOCAsrOzlZqa2iQNXkkhISEKCQlp7jYAAMBV4NeVnK5duyouLs5nXe/evVVaWipJioyMlCSVlZX51JSVldljkZGRKi8v9xk/e/asTpw44VPT2Bzn7uNCNQ3jAADg+uZXyPnOd76jQ4cO+az76KOP1KNHD0lSz549FRkZqcLCQnvc6/Vqx44dcrlckiSXy6XKykoVFxfbNZs3b1Z9fb0SExPtmm3btunMmTN2TUFBgXr16mU/yeVyuXz201DTsB8AAHB98yvkTJkyRe+++65+/vOf6y9/+YtWrlypV155Renp6ZKkgIAATZ48WS+88ILWr1+v/fv3a+TIkYqKitLQoUMlfX3l595779WYMWO0c+dOvfPOO5owYYKGDx+uqKgoSdKPf/xjBQcHKy0tTQcPHtTq1au1cOFCZWRk2L1MmjRJ+fn5evnll1VSUqLZs2dr9+7dmjBhwhX6aAAAQEvm1z05AwYM0Ouvv67MzEzNmTNHPXv21IIFCzRixAi7Ztq0aaqurtbYsWNVWVmpO+64Q/n5+QoNDbVrXnvtNU2YMEH33HOPAgMDlZKSokWLFtnjTqdTb775ptLT0xUfH69OnTopKyvL5106gwYN0sqVKzVz5kw9++yzuummm7Ru3Trdcsstl/N5AAAAQ/j1nhzTXOxz9peD9+QAAHBlNcl7cgAAAFoKQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCS/Qs7s2bMVEBDgs8TGxtrjp0+fVnp6ujp27Kh27dopJSVFZWVlPnOUlpYqOTlZbdq0UZcuXTR16lSdPXvWp2bLli3q37+/QkJCdOONNyonJ+e8XpYsWaKYmBiFhoYqMTFRO3fu9OdQAACA4fy+kvNv//Zv+vzzz+3lz3/+sz02ZcoUvfHGG1q7dq22bt2qY8eO6aGHHrLH6+rqlJycrNraWm3fvl0rVqxQTk6OsrKy7JojR44oOTlZgwcP1t69ezV58mQ98cQT2rRpk12zevVqZWRkaNasWdqzZ4/69u0rt9ut8vLyS/0cAACAYQIsy7Iutnj27Nlat26d9u7de95YVVWVOnfurJUrV+rhhx+WJJWUlKh3794qKirSwIEDtXHjRt1///06duyYIiIiJEnZ2dmaPn26KioqFBwcrOnTpysvL08HDhyw5x4+fLgqKyuVn58vSUpMTNSAAQO0ePFiSVJ9fb2io6M1ceJEzZgx46IP3uv1yul0qqqqSg6H46K380fMjLwmmfdq++TF5OZuAQAASRf/+9vvKzmHDx9WVFSUvvWtb2nEiBEqLS2VJBUXF+vMmTNKSkqya2NjY9W9e3cVFRVJkoqKitSnTx874EiS2+2W1+vVwYMH7Zpz52ioaZijtrZWxcXFPjWBgYFKSkqyay6kpqZGXq/XZwEAAGbyK+QkJiYqJydH+fn5WrZsmY4cOaI777xTX375pTwej4KDgxUeHu6zTUREhDwejyTJ4/H4BJyG8Yaxb6rxer06deqUjh8/rrq6ukZrGua4kLlz58rpdNpLdHS0P4cPAABakFb+FN933332f996661KTExUjx49tGbNGoWFhV3x5q60zMxMZWRk2D97vV6CDgAAhrqsR8jDw8N188036y9/+YsiIyNVW1uryspKn5qysjJFRkZKkiIjI8972qrh539V43A4FBYWpk6dOikoKKjRmoY5LiQkJEQOh8NnAQAAZrqskHPy5El9/PHH6tq1q+Lj49W6dWsVFhba44cOHVJpaalcLpckyeVyaf/+/T5PQRUUFMjhcCguLs6uOXeOhpqGOYKDgxUfH+9TU19fr8LCQrsGAADAr5DzzDPPaOvWrfrkk0+0fft2PfjggwoKCtKjjz4qp9OptLQ0ZWRk6K233lJxcbFGjRoll8ulgQMHSpKGDBmiuLg4PfbYY3r//fe1adMmzZw5U+np6QoJCZEkjRs3Tn/96181bdo0lZSUaOnSpVqzZo2mTJli95GRkaHf/va3WrFihT788EONHz9e1dXVGjVq1BX8aAAAQEvm1z05n332mR599FH9/e9/V+fOnXXHHXfo3XffVefOnSVJ8+fPV2BgoFJSUlRTUyO3262lS5fa2wcFBSk3N1fjx4+Xy+VS27ZtlZqaqjlz5tg1PXv2VF5enqZMmaKFCxeqW7duWr58udxut10zbNgwVVRUKCsrSx6PR/369VN+fv55NyMDAIDrl1/vyTEN78m5eLwnBwBwrWiy9+QAAAC0BIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIlxVyXnzxRQUEBGjy5Mn2utOnTys9PV0dO3ZUu3btlJKSorKyMp/tSktLlZycrDZt2qhLly6aOnWqzp4961OzZcsW9e/fXyEhIbrxxhuVk5Nz3v6XLFmimJgYhYaGKjExUTt37rycwwEAAAa55JCza9cu/eY3v9Gtt97qs37KlCl64403tHbtWm3dulXHjh3TQw89ZI/X1dUpOTlZtbW12r59u1asWKGcnBxlZWXZNUeOHFFycrIGDx6svXv3avLkyXriiSe0adMmu2b16tXKyMjQrFmztGfPHvXt21dut1vl5eWXekgAAMAgAZZlWf5udPLkSfXv319Lly7VCy+8oH79+mnBggWqqqpS586dtXLlSj388MOSpJKSEvXu3VtFRUUaOHCgNm7cqPvvv1/Hjh1TRESEJCk7O1vTp09XRUWFgoODNX36dOXl5enAgQP2PocPH67Kykrl5+dLkhITEzVgwAAtXrxYklRfX6/o6GhNnDhRM2bMuKjj8Hq9cjqdqqqqksPh8PdjuCgxM/KaZN6r7ZMXk5u7BQAAJF387+9LupKTnp6u5ORkJSUl+awvLi7WmTNnfNbHxsaqe/fuKioqkiQVFRWpT58+dsCRJLfbLa/Xq4MHD9o1/zy32+2256itrVVxcbFPTWBgoJKSkuyaxtTU1Mjr9fosAADATK383WDVqlXas2ePdu3add6Yx+NRcHCwwsPDfdZHRETI4/HYNecGnIbxhrFvqvF6vTp16pS++OIL1dXVNVpTUlJywd7nzp2rn/70pxd3oAAAoEXz60rO0aNHNWnSJL322msKDQ1tqp6aTGZmpqqqquzl6NGjzd0SAABoIn6FnOLiYpWXl6t///5q1aqVWrVqpa1bt2rRokVq1aqVIiIiVFtbq8rKSp/tysrKFBkZKUmKjIw872mrhp//VY3D4VBYWJg6deqkoKCgRmsa5mhMSEiIHA6HzwIAAMzkV8i55557tH//fu3du9deEhISNGLECPu/W7durcLCQnubQ4cOqbS0VC6XS5Lkcrm0f/9+n6egCgoK5HA4FBcXZ9ecO0dDTcMcwcHBio+P96mpr69XYWGhXQMAAK5vft2T0759e91yyy0+69q2bauOHTva69PS0pSRkaEOHTrI4XBo4sSJcrlcGjhwoCRpyJAhiouL02OPPaZ58+bJ4/Fo5syZSk9PV0hIiCRp3LhxWrx4saZNm6bRo0dr8+bNWrNmjfLy/vGkUkZGhlJTU5WQkKDbb79dCxYsUHV1tUaNGnVZHwgAADCD3zce/yvz589XYGCgUlJSVFNTI7fbraVLl9rjQUFBys3N1fjx4+VyudS2bVulpqZqzpw5dk3Pnj2Vl5enKVOmaOHCherWrZuWL18ut9tt1wwbNkwVFRXKysqSx+NRv379lJ+ff97NyAAA4Pp0Se/JMQXvybl4vCcHAHCtaNL35AAAAFzrCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjtWruBoCrKWZGXnO3cNk+eTG5uVsAgBaBKzkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJH8CjnLli3TrbfeKofDIYfDIZfLpY0bN9rjp0+fVnp6ujp27Kh27dopJSVFZWVlPnOUlpYqOTlZbdq0UZcuXTR16lSdPXvWp2bLli3q37+/QkJCdOONNyonJ+e8XpYsWaKYmBiFhoYqMTFRO3fu9OdQAACA4fwKOd26ddOLL76o4uJi7d69W3fffbceeOABHTx4UJI0ZcoUvfHGG1q7dq22bt2qY8eO6aGHHrK3r6urU3Jysmpra7V9+3atWLFCOTk5ysrKsmuOHDmi5ORkDR48WHv37tXkyZP1xBNPaNOmTXbN6tWrlZGRoVmzZmnPnj3q27ev3G63ysvLL/fzAAAAhgiwLMu6nAk6dOigl156SQ8//LA6d+6slStX6uGHH5YklZSUqHfv3ioqKtLAgQO1ceNG3X///Tp27JgiIiIkSdnZ2Zo+fboqKioUHBys6dOnKy8vTwcOHLD3MXz4cFVWVio/P1+SlJiYqAEDBmjx4sWSpPr6ekVHR2vixImaMWPGRffu9XrldDpVVVUlh8NxOR/DBZnwNQKSOV8lYML5MOVcAMClutjf35d8T05dXZ1WrVql6upquVwuFRcX68yZM0pKSrJrYmNj1b17dxUVFUmSioqK1KdPHzvgSJLb7ZbX67WvBhUVFfnM0VDTMEdtba2Ki4t9agIDA5WUlGTXXEhNTY28Xq/PAgAAzOR3yNm/f7/atWunkJAQjRs3Tq+//rri4uLk8XgUHBys8PBwn/qIiAh5PB5Jksfj8Qk4DeMNY99U4/V6derUKR0/flx1dXWN1jTMcSFz586V0+m0l+joaH8PHwAAtBB+h5xevXpp79692rFjh8aPH6/U1FR98MEHTdHbFZeZmamqqip7OXr0aHO3BAAAmkgrfzcIDg7WjTfeKEmKj4/Xrl27tHDhQg0bNky1tbWqrKz0uZpTVlamyMhISVJkZOR5T0E1PH11bs0/P5FVVlYmh8OhsLAwBQUFKSgoqNGahjkuJCQkRCEhIf4eMgAAaIEu+z059fX1qqmpUXx8vFq3bq3CwkJ77NChQyotLZXL5ZIkuVwu7d+/3+cpqIKCAjkcDsXFxdk1587RUNMwR3BwsOLj431q6uvrVVhYaNcAAAD4dSUnMzNT9913n7p3764vv/xSK1eu1JYtW7Rp0yY5nU6lpaUpIyNDHTp0kMPh0MSJE+VyuTRw4EBJ0pAhQxQXF6fHHntM8+bNk8fj0cyZM5Wenm5fYRk3bpwWL16sadOmafTo0dq8ebPWrFmjvLx/PBWTkZGh1NRUJSQk6Pbbb9eCBQtUXV2tUaNGXcGPBgAAtGR+hZzy8nKNHDlSn3/+uZxOp2699VZt2rRJ3//+9yVJ8+fPV2BgoFJSUlRTUyO3262lS5fa2wcFBSk3N1fjx4+Xy+VS27ZtlZqaqjlz5tg1PXv2VF5enqZMmaKFCxeqW7duWr58udxut10zbNgwVVRUKCsrSx6PR/369VN+fv55NyMDAIDr12W/J6cl4z05F8+Ud7OYcD5MORcAcKma/D05AAAA1zJCDgAAMBIhBwAAGImQAwAAjETIAQAARvL7jccAcCXwpBuApsaVHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjORXyJk7d64GDBig9u3bq0uXLho6dKgOHTrkU3P69Gmlp6erY8eOateunVJSUlRWVuZTU1paquTkZLVp00ZdunTR1KlTdfbsWZ+aLVu2qH///goJCdGNN96onJyc8/pZsmSJYmJiFBoaqsTERO3cudOfwwEAAAbzK+Rs3bpV6enpevfdd1VQUKAzZ85oyJAhqq6utmumTJmiN954Q2vXrtXWrVt17NgxPfTQQ/Z4XV2dkpOTVVtbq+3bt2vFihXKyclRVlaWXXPkyBElJydr8ODB2rt3ryZPnqwnnnhCmzZtsmtWr16tjIwMzZo1S3v27FHfvn3ldrtVXl5+OZ8HAAAwRIBlWdalblxRUaEuXbpo69atuuuuu1RVVaXOnTtr5cqVevjhhyVJJSUl6t27t4qKijRw4EBt3LhR999/v44dO6aIiAhJUnZ2tqZPn66KigoFBwdr+vTpysvL04EDB+x9DR8+XJWVlcrPz5ckJSYmasCAAVq8eLEkqb6+XtHR0Zo4caJmzJjRaL81NTWqqamxf/Z6vYqOjlZVVZUcDselfgzfKGZGXpPMe7V98mJyc7dwRZhwPjgX1w5TzgXQ0ni9Xjmdzn/5+/uy7smpqqqSJHXo0EGSVFxcrDNnzigpKcmuiY2NVffu3VVUVCRJKioqUp8+feyAI0lut1ter1cHDx60a86do6GmYY7a2loVFxf71AQGBiopKcmuaczcuXPldDrtJTo6+nIOHwAAXMMuOeTU19dr8uTJ+s53vqNbbrlFkuTxeBQcHKzw8HCf2oiICHk8Hrvm3IDTMN4w9k01Xq9Xp06d0vHjx1VXV9doTcMcjcnMzFRVVZW9HD161P8DBwAALUKrS90wPT1dBw4c0J///Ocr2U+TCgkJUUhISHO3AQAAroJLupIzYcIE5ebm6q233lK3bt3s9ZGRkaqtrVVlZaVPfVlZmSIjI+2af37aquHnf1XjcDgUFhamTp06KSgoqNGahjkAAMD1za+QY1mWJkyYoNdff12bN29Wz549fcbj4+PVunVrFRYW2usOHTqk0tJSuVwuSZLL5dL+/ft9noIqKCiQw+FQXFycXXPuHA01DXMEBwcrPj7ep6a+vl6FhYV2DQAAuL759eeq9PR0rVy5Uv/7v/+r9u3b2/e/OJ1OhYWFyel0Ki0tTRkZGerQoYMcDocmTpwol8ulgQMHSpKGDBmiuLg4PfbYY5o3b548Ho9mzpyp9PR0+09J48aN0+LFizVt2jSNHj1amzdv1po1a5SX94+nMTIyMpSamqqEhATdfvvtWrBggaqrqzVq1Kgr9dkAAIAWzK+Qs2zZMknS9773PZ/1r776qh5//HFJ0vz58xUYGKiUlBTV1NTI7XZr6dKldm1QUJByc3M1fvx4uVwutW3bVqmpqZozZ45d07NnT+Xl5WnKlClauHChunXrpuXLl8vtdts1w4YNU0VFhbKysuTxeNSvXz/l5+efdzMyAAC4Pl3We3Jauot9zv5ymPAuEMmc94GYcD44F9cOU84F0NJclffkAAAAXKsIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkfwOOdu2bdMPf/hDRUVFKSAgQOvWrfMZtyxLWVlZ6tq1q8LCwpSUlKTDhw/71Jw4cUIjRoyQw+FQeHi40tLSdPLkSZ+affv26c4771RoaKiio6M1b96883pZu3atYmNjFRoaqj59+mjDhg3+Hg4AADCU3yGnurpaffv21ZIlSxodnzdvnhYtWqTs7Gzt2LFDbdu2ldvt1unTp+2aESNG6ODBgyooKFBubq62bdumsWPH2uNer1dDhgxRjx49VFxcrJdeekmzZ8/WK6+8Ytds375djz76qNLS0vTee+9p6NChGjp0qA4cOODvIQEAAAMFWJZlXfLGAQF6/fXXNXToUElfX8WJiorS008/rWeeeUaSVFVVpYiICOXk5Gj48OH68MMPFRcXp127dikhIUGSlJ+frx/84Af67LPPFBUVpWXLlum5556Tx+NRcHCwJGnGjBlat26dSkpKJEnDhg1TdXW1cnNz7X4GDhyofv36KTs7+6L693q9cjqdqqqqksPhuNSP4RvFzMhrknmvtk9eTG7uFq4IE84H5+LaYcq5AFqai/39fUXvyTly5Ig8Ho+SkpLsdU6nU4mJiSoqKpIkFRUVKTw83A44kpSUlKTAwEDt2LHDrrnrrrvsgCNJbrdbhw4d0hdffGHXnLufhpqG/TSmpqZGXq/XZwEAAGa6oiHH4/FIkiIiInzWR0RE2GMej0ddunTxGW/VqpU6dOjgU9PYHOfu40I1DeONmTt3rpxOp71ER0f7e4gAAKCFuK6ersrMzFRVVZW9HD16tLlbAgAATeSKhpzIyEhJUllZmc/6srIyeywyMlLl5eU+42fPntWJEyd8ahqb49x9XKimYbwxISEhcjgcPgsAADBTqys5Wc+ePRUZGanCwkL169dP0tc3B+3YsUPjx4+XJLlcLlVWVqq4uFjx8fGSpM2bN6u+vl6JiYl2zXPPPaczZ86odevWkqSCggL16tVLN9xwg11TWFioyZMn2/svKCiQy+W6kocEAMYz4SZwiRvBcT6/r+ScPHlSe/fu1d69eyV9fbPx3r17VVpaqoCAAE2ePFkvvPCC1q9fr/3792vkyJGKioqyn8Dq3bu37r33Xo0ZM0Y7d+7UO++8owkTJmj48OGKioqSJP34xz9WcHCw0tLSdPDgQa1evVoLFy5URkaG3cekSZOUn5+vl19+WSUlJZo9e7Z2796tCRMmXP6nAgAAWjy/r+Ts3r1bgwcPtn9uCB6pqanKycnRtGnTVF1drbFjx6qyslJ33HGH8vPzFRoaam/z2muvacKECbrnnnsUGBiolJQULVq0yB53Op168803lZ6ervj4eHXq1ElZWVk+79IZNGiQVq5cqZkzZ+rZZ5/VTTfdpHXr1umWW265pA8CAACYxe+Q873vfU/f9GqdgIAAzZkzR3PmzLlgTYcOHbRy5cpv3M+tt96qt99++xtrHnnkET3yyCPf3DAAALguXVdPVwEAgOsHIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJGu6BuPAQDApePt01cWV3IAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBILT7kLFmyRDExMQoNDVViYqJ27tzZ3C0BAIBrQIsOOatXr1ZGRoZmzZqlPXv2qG/fvnK73SovL2/u1gAAQDNr0SHnV7/6lcaMGaNRo0YpLi5O2dnZatOmjX73u981d2sAAKCZtWruBi5VbW2tiouLlZmZaa8LDAxUUlKSioqKGt2mpqZGNTU19s9VVVWSJK/X22R91td81WRzX01N+RldTSacD87FtYNzcW0x4XxwLvyb37Ksb6xrsSHn+PHjqqurU0REhM/6iIgIlZSUNLrN3Llz9dOf/vS89dHR0U3So0mcC5q7AzTgXFw7OBfXFs7HteNqnYsvv/xSTqfzguMtNuRciszMTGVkZNg/19fX68SJE+rYsaMCAgKasbNL5/V6FR0draNHj8rhcDR3O9c1zsW1hfNx7eBcXDtMOReWZenLL79UVFTUN9a12JDTqVMnBQUFqayszGd9WVmZIiMjG90mJCREISEhPuvCw8ObqsWryuFwtOj/YU3Cubi2cD6uHZyLa4cJ5+KbruA0aLE3HgcHBys+Pl6FhYX2uvr6ehUWFsrlcjVjZwAA4FrQYq/kSFJGRoZSU1OVkJCg22+/XQsWLFB1dbVGjRrV3K0BAIBm1qJDzrBhw1RRUaGsrCx5PB7169dP+fn5592MbLKQkBDNmjXrvD/D4erjXFxbOB/XDs7FteN6OxcB1r96/goAAKAFarH35AAAAHwTQg4AADASIQcAABiJkAMAAIxEyAEANCmeb0FzadGPkAMArn0hISF6//331bt37+Zu5bpz/Phx/e53v1NRUZE8Ho8kKTIyUoMGDdLjjz+uzp07N3OHTYtHyFuYU6dOqbi4WB06dFBcXJzP2OnTp7VmzRqNHDmymbq7vnz44Yd699135XK5FBsbq5KSEi1cuFA1NTX6yU9+orvvvru5W8T/d/ToUc2aNUu/+93vmrsVo5373YDnWrhwoX7yk5+oY8eOkqRf/epXV7Ot69auXbvkdrvVpk0bJSUl2e+QKysrU2Fhob766itt2rRJCQkJzdxp0yHktCAfffSRhgwZotLSUgUEBOiOO+7QqlWr1LVrV0lf/48bFRWlurq6Zu7UfPn5+XrggQfUrl07ffXVV3r99dc1cuRI9e3bV/X19dq6davefPNNgs414v3331f//v35t9HEAgMD1bdv3/O+E3Dr1q1KSEhQ27ZtFRAQoM2bNzdPg9eZgQMHqm/fvsrOzj7vS6gty9K4ceO0b98+FRUVNVOHTY+Q04I8+OCDOnPmjHJyclRZWanJkyfrgw8+0JYtW9S9e3dCzlU0aNAg3X333XrhhRe0atUqPfXUUxo/frx+9rOfSfr6G++Li4v15ptvNnOn14f169d/4/hf//pXPf300/zbaGIvvviiXnnlFS1fvtwn4Ldu3Vrvv//+eVef0bTCwsL03nvvKTY2ttHxkpIS3XbbbTp16tRV7uwqstBidOnSxdq3b5/9c319vTVu3Dire/fu1scff2x5PB4rMDCwGTu8fjgcDuvw4cOWZVlWXV2d1apVK2vPnj32+P79+62IiIjmau+6ExAQYAUGBloBAQEXXPi3cXXs3LnTuvnmm62nn37aqq2ttSzLslq1amUdPHiwmTu7/sTExFgrVqy44PiKFSusHj16XL2GmgFPV7Ugp06dUqtW/7hXPCAgQMuWLdMPf/hDffe739VHH33UjN1dfxou/wYGBio0NFROp9Mea9++vaqqqpqrtetO165d9ac//Un19fWNLnv27GnuFq8bAwYMUHFxsSoqKpSQkKADBw6c96cSXB3PPPOMxo4dq0mTJmn9+vXasWOHduzYofXr12vSpEkaN26cpk2b1txtNimermpBYmNjtXv37vOeUFi8eLEk6d///d+bo63rUkxMjA4fPqxvf/vbkqSioiJ1797dHi8tLbXvlULTi4+PV3FxsR544IFGxwMCAniM+Spq166dVqxYoVWrVikpKYk/EzaT9PR0derUSfPnz9fSpUvt8xAUFKT4+Hjl5OToRz/6UTN32bS4J6cFmTt3rt5++21t2LCh0fGnnnpK2dnZqq+vv8qdXX+ys7MVHR2t5OTkRsefffZZlZeXa/ny5Ve5s+vT22+/rerqat17772NjldXV2v37t367ne/e5U7w2effabi4mIlJSWpbdu2zd3OdevMmTM6fvy4JKlTp05q3bp1M3d0dRByAACAkbgnBwAAGImQAwAAjETIAQAARiLkAAAAIxFyABhjy5YtCggIUGVlZXO3AuAaQMgBcMVVVFRo/Pjx6t69u0JCQhQZGSm326133nnniu3je9/7niZPnuyzbtCgQfr88899XszYXB5//HENHTq0udsArmu8DBDAFZeSkqLa2lqtWLFC3/rWt+xvPf773//epPsNDg5WZGRkk+4DQAvSrF8qAcA4X3zxhSXJ2rJlyzfWpKWlWZ06dbLat29vDR482Nq7d689PmvWLKtv377Wf//3f1s9evSwHA6HNWzYMMvr9VqWZVmpqamWJJ/lyJEj1ltvvWVJsr744gvLsizr1VdftZxOp/XGG29YN998sxUWFmalpKRY1dXVVk5OjtWjRw8rPDzcmjhxonX27Fl7/6dPn7aefvppKyoqymrTpo11++23W2+99ZY93jBvfn6+FRsba7Vt29Zyu93WsWPH7P7/ub9ztwdwdfDnKgBXVLt27dSuXTutW7dONTU1jdY88sgjKi8v18aNG1VcXKz+/fvrnnvu0YkTJ+yajz/+WOvWrVNubq5yc3O1detWvfjii5KkhQsXyuVyacyYMfr888/1+eefKzo6utF9ffXVV1q0aJFWrVql/Px8bdmyRQ8++KA2bNigDRs26Pe//71+85vf6I9//KO9zYQJE1RUVKRVq1Zp3759euSRR3Tvvffq8OHDPvP+8pe/1O9//3tt27ZNpaWleuaZZyR9/Z1BP/rRj3Tvvffa/Q0aNOiyP1sAfmrulAXAPH/84x+tG264wQoNDbUGDRpkZWZmWu+//75lWZb19ttvWw6Hwzp9+rTPNt/+9ret3/zmN5ZlfX0lpE2bNvaVG8uyrKlTp1qJiYn2z9/97netSZMm+czR2JUcSdZf/vIXu+bJJ5+02rRpY3355Zf2OrfbbT355JOWZVnWp59+agUFBVl/+9vffOa+5557rMzMzAvOu2TJEp9vnk9NTbUeeOCBi/q8ADQN7skBcMWlpKQoOTlZb7/9tt59911t3LhR8+bN0/Lly1VdXa2TJ0+qY8eOPtucOnVKH3/8sf1zTEyM2rdvb//ctWtXlZeX+91LmzZt7C9SlaSIiAjFxMSoXbt2Pusa5t6/f7/q6up08803+8xTU1Pj0/M/z3up/QFoOoQcAE0iNDRU3//+9/X9739fzz//vJ544gnNmjVLTz31lLp27aotW7act014eLj93//8BYIBAQGX9OWzjc3zTXOfPHlSQUFBKi4uVlBQkE/ducGosTksvgoQuKYQcgBcFXFxcVq3bp369+8vj8ejVq1aKSYm5pLnCw4OVl1d3ZVr8P+77bbbVFdXp/Lyct15552XPE9T9Qfg4nHjMYAr6u9//7vuvvtu/eEPf9C+fft05MgRrV27VvPmzdMDDzygpKQkuVwuDR06VG+++aY++eQTbd++Xc8995x279590fuJiYnRjh079Mknn+j48eOXdJWnMTfffLNGjBihkSNH6k9/+pOOHDminTt3au7cucrLy/Orv3379unQoUM6fvy4zpw5c0X6A3DxCDkArqh27dopMTFR8+fP11133aVbbrlFzz//vMaMGaPFixcrICBAGzZs0F133aVRo0bp5ptv1vDhw/Xpp58qIiLiovfzzDPPKCgoSHFxcercubNKS0uv2DG8+uqrGjlypJ5++mn16tVLQ4cO1a5du9S9e/eLnmPMmDHq1auXEhIS1Llz5yv6IkQAFyfA4o/IAADAQFzJAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR/h9yirrFpiHKywAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 156060, seq len: 512\n"
     ]
    }
   ],
   "source": [
    "seq_len = 512\n",
    "num_samples = len(df)\n",
    "\n",
    "print('Number of samples: {}, seq len: {}'.format(num_samples, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(df['Phrase'].tolist(), \n",
    "                   max_length=seq_len, \n",
    "                   truncation=True,\n",
    "                   padding='max_length', \n",
    "                   add_special_tokens=True,\n",
    "                   return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101, 22572, 12148, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/movie-xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "\n",
    "with open('./data/movie-xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = df['Sentiment'].values\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2 = [0, 0, 1, 0, 0]\n",
    "    4 = [0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((num_samples, arr.max() + 1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[np.arange(num_samples), arr] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/movie-labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><span style='color:#F1C40F'>|</span>Input pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/movie-xids.npy', 'rb') as f:\n",
    "    Xids = np.load(f, allow_pickle=True)\n",
    "with open('./data/movie-xmask.npy', 'rb') as f:\n",
    "    Xmask = np.load(f, allow_pickle=True)\n",
    "with open('./data/movie-labels.npy', 'rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{input_ids, attention_mask}, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(map_func)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8778"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int((Xids.shape[0] / batch_size) * split)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sviat\\AppData\\Local\\Temp\\ipykernel_7036\\952094157.py:1: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.save(train_ds, '/train')\n",
    "tf.data.experimental.save(val_ds, '/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec == val_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sviat\\AppData\\Local\\Temp\\ipykernel_7036\\987423320.py:1: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.experimental.load('/train', element_spec=train_ds.element_spec)\n",
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><span style='color:#F1C40F'>|</span>Build and train</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sviat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108310272 (413.17 MB)\n",
      "Trainable params: 108310272 (413.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "# we can view the model using the summary method\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
    "embeddings = bert.bert(input_ids, attention_mask=mask)[1]  # access final activations (alread max-pooled) [1]\n",
    "# convert bert embeddings into 5 output classes\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 512)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 512)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bert (TFBertMainLayer)      TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
      "                             ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 512, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 787456    ['bert[0][1]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, 5)                    5125      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109102853 (416.19 MB)\n",
      "Trainable params: 792581 (3.02 MB)\n",
      "Non-trainable params: 108310272 (413.17 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "# (optional) freeze bert layer\n",
    "model.layers[2].trainable = False\n",
    "\n",
    "# print out model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 512)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 512)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)      TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
      "                             ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 512, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 787456    ['bert[0][1]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, 5)                    5125      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109102853 (416.19 MB)\n",
      "Trainable params: 792581 (3.02 MB)\n",
      "Non-trainable params: 108310272 (413.17 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=1e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.int32, name=None),\n",
    "                 'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)},\n",
    "                tf.TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))\n",
    "\n",
    "# load the training and validation sets\n",
    "train_ds = tf.data.experimental.load('/train', element_spec=element_spec)\n",
    "val_ds = tf.data.experimental.load('/val', element_spec=element_spec)\n",
    "\n",
    "# view the input format\n",
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It takes a lot of computing power to do this, I don't have that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\sviat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sviat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 170/8778 [..............................] - ETA: 21:29:10 - loss: 1.3201 - accuracy: 0.5121"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><span style='color:#F1C40F'>|</span>Load and predict</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('sentiment_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(text):\n",
    "    tokens = tokenizer.encode_plus(text, max_length=512,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_token_type_ids=False,\n",
    "                                   return_tensors='tf')\n",
    "    # tokenizer returns int32 tensors, we need to return float64, so we use tf.cast\n",
    "    return {'input_ids': tf.cast(tokens['input_ids'], tf.float64),\n",
    "            'attention_mask': tf.cast(tokens['attention_mask'], tf.float64)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict(prep_data(\"hello world\"))[0]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine effort .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId  \\\n",
       "0    156061        8545   \n",
       "1    156062        8545   \n",
       "2    156063        8545   \n",
       "3    156064        8545   \n",
       "4    156065        8545   \n",
       "\n",
       "                                                   Phrase  \n",
       "0  An intermittently pleasing but mostly routine effort .  \n",
       "1    An intermittently pleasing but mostly routine effort  \n",
       "2                                                      An  \n",
       "3       intermittently pleasing but mostly routine effort  \n",
       "4              intermittently pleasing but mostly routine  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('./data/test.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['SentenceId'], keep='first')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = None\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # get token tensors\n",
    "    tokens = prep_data(row['Phrase'])\n",
    "    # get probabilities\n",
    "    probs = model.predict(tokens)\n",
    "    # find argmax for winning class\n",
    "    pred = np.argmax(probs)\n",
    "    # add to dataframe\n",
    "    df.at[i, 'Sentiment'] = pred\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
